{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('D:\\\\personal_repositories\\\\travel_mode_detection\\\\artifacts\\\\decision_tree_trained_model.pkl')\n",
    "class_encoder = joblib.load('D:\\\\personal_repositories\\\\travel_mode_detection\\\\artifacts\\\\label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the shape file\n",
    "shapefile_path = 'U:\\Projects\\Huq\\Faraz\\huq_city_data\\Shapefiles\\msoa_intzone_boundaries\\glasgow\\msoa_glasgow.shp'\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "gdf = gdf.to_crs(epsg=4326)\n",
    "gdf.index\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2021\n",
    "data_path = f'U:\\Projects\\Huq\\Faraz\\\\travel_mode_detection\\Glasgow\\\\{year}\\\\processed_trip_points_data.csv'\n",
    "processed_data = pd.read_csv(data_path)\n",
    "processed_data = processed_data[['year', 'distance_threshold', 'uid', 'imd_quintile', 'trip_id',\n",
    "       'total_active_days', 'lat', 'lng', 'org_lat', 'org_lng',\n",
    "       'dest_lat', 'dest_lng', 'datetime', 'num_of_impressions', 'time_taken',\n",
    "       'prev_lat', 'prev_long', 'distance_covered', 'speed', 'date', 'hour',\n",
    "       'speed_z_score', 'new_speed', 'accelaration', 'jerk', 'bearing',\n",
    "       'angular_deviation', 'month', 'is_weekend', 'hour_category',\n",
    "       'start_end_at_bus_stop', 'start_end_at_train_stop',\n",
    "       'start_end_at_metro_stop', 'found_at_green_space',\n",
    "       'straightness_index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attributes = ['month',\n",
    "          'speed_median','speed_pct_95','speed_std',\t\n",
    "          'acceleration_median','acceleration_pct_95','acceleration_std',\n",
    "          'jerk_median','jerk_pct_95','jerk_std',\n",
    "          'angular_dev_median','angular_dev_pct_95','angular_dev_std',\n",
    "          'straightness_index','distance_covered','start_end_at_bus_stop','start_end_at_train_stop','start_end_at_metro_stop','found_at_green_space','is_weekend','hour_category']\n",
    "\n",
    "data_path = f'U:\\Projects\\Huq\\Faraz\\\\travel_mode_detection\\Glasgow\\\\{year}\\\\huq_stats_df_for_ml.csv'\n",
    "data = pd.read_csv(data_path, parse_dates=['datetime'])\n",
    "data['month'] = data['datetime'].dt.month\n",
    "# keep the mode of month for each uid and trip_id\n",
    "data['month'] = data.groupby(['uid', 'trip_id'])['month'].transform(lambda x: x.mode()[0]) # some night trips change the month. So, we keep the mode of month for each trip\n",
    "data = data.drop_duplicates(subset=attributes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(data[attributes])\n",
    "pred = class_encoder.inverse_transform(pred)\n",
    "data['travel_mode'] = pred\n",
    "\n",
    "processed_data = processed_data.merge(data[['uid', 'trip_id', 'travel_mode']], on=['uid', 'trip_id'], how='left')\n",
    "op_df = processed_data[['uid', 'trip_id','org_lat', 'org_lng', 'dest_lat', 'dest_lng', 'lat', 'lng', 'datetime', 'travel_mode']]\n",
    "\n",
    "# Add origin geo code\n",
    "geometry = [Point(xy) for xy in zip(op_df['org_lng'], op_df['org_lat'])]\n",
    "op_df = gpd.GeoDataFrame(op_df, crs=\"EPSG:4326\", geometry=geometry)\n",
    "op_df = op_df.sjoin(gdf[['geo_code', 'geometry']],  how='left', predicate='intersects')\n",
    "op_df = op_df.rename(columns={'geo_code': 'org_geo_code'})\n",
    "op_df = op_df.drop(columns=['geometry', 'index_right'])\n",
    "\n",
    "\n",
    "# Add destination geo code\n",
    "geometry = [Point(xy) for xy in zip(op_df['dest_lng'], op_df['dest_lat'])]\n",
    "op_df = gpd.GeoDataFrame(op_df, crs=\"EPSG:4326\", geometry=geometry)\n",
    "op_df = op_df.sjoin(gdf[['geo_code', 'geometry']],  how='left', predicate='intersects')\n",
    "op_df = op_df.rename(columns={'geo_code': 'dest_geo_code'})\n",
    "op_df = op_df.drop(columns=['geometry', 'index_right'])\n",
    "\n",
    "op_df.loc[:, 'trip_num'] = pd.factorize(op_df[['uid', 'trip_id']].apply(tuple, axis=1))[0] + 1\n",
    "op_df = op_df.drop(columns=['uid', 'trip_id'])\n",
    "op_df = op_df[['trip_num', 'org_geo_code', 'dest_geo_code','lat', 'lng', 'datetime', 'travel_mode']]\n",
    "op_df = op_df.rename(columns={'trip_num': 'trip_id', 'lat': 'tp_lat', 'lng': 'tp_lng'})\n",
    "op_df = op_df.dropna(subset = ['travel_mode'])\n",
    "assert op_df['travel_mode'].isna().sum() == 0\n",
    "op_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_path = f'U:\\Projects\\Huq\\Faraz\\\\travel_mode_detection\\Glasgow\\\\{year}\\\\validation'\n",
    "os.makedirs(op_path, exist_ok=True)\n",
    "op_df.to_csv(f'{op_path}\\\\predicted_travel_modes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = op_df.drop_duplicates(subset=['trip_id'])\n",
    "# calculate the percentage of each travel mode\n",
    "tdf['travel_mode'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2019\n",
    "op_path = f'U:\\Projects\\Huq\\Faraz\\\\travel_mode_detection\\Glasgow\\\\{year}\\\\validation'\n",
    "tmd_df1 = pd.read_csv(f'{op_path}\\\\predicted_travel_modes.csv')\n",
    "\n",
    "year = 2020\n",
    "op_path = f'U:\\Projects\\Huq\\Faraz\\\\travel_mode_detection\\Glasgow\\\\{year}\\\\validation'\n",
    "tmd_df2 = pd.read_csv(f'{op_path}\\\\predicted_travel_modes.csv')\n",
    "\n",
    "year = 2021\n",
    "op_path = f'U:\\Projects\\Huq\\Faraz\\\\travel_mode_detection\\Glasgow\\\\{year}\\\\validation'\n",
    "tmd_df3 = pd.read_csv(f'{op_path}\\\\predicted_travel_modes.csv')\n",
    "\n",
    "year = 2022\n",
    "op_path = f'U:\\Projects\\Huq\\Faraz\\\\travel_mode_detection\\Glasgow\\\\{year}\\\\validation'\n",
    "tmd_df4 = pd.read_csv(f'{op_path}\\\\predicted_travel_modes.csv')\n",
    "\n",
    "year = 2023\n",
    "op_path = f'U:\\Projects\\Huq\\Faraz\\\\travel_mode_detection\\Glasgow\\\\{year}\\\\validation'\n",
    "tmd_df5 = pd.read_csv(f'{op_path}\\\\predicted_travel_modes.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the percentage of each travel mode for each year an create a dataframe the contains columns year, column for each travel mode and the percentage of that travel mode\n",
    "tmd_df1['year'] = 2019\n",
    "tmd_df2['year'] = 2020\n",
    "tmd_df3['year'] = 2021\n",
    "tmd_df4['year'] = 2022\n",
    "tmd_df5['year'] = 2023\n",
    "\n",
    "tmd_df1 = tmd_df1.drop_duplicates(subset=['trip_id'])\n",
    "tmd_df2 = tmd_df2.drop_duplicates(subset=['trip_id'])\n",
    "tmd_df3 = tmd_df3.drop_duplicates(subset=['trip_id'])\n",
    "tmd_df4 = tmd_df4.drop_duplicates(subset=['trip_id'])\n",
    "tmd_df5 = tmd_df5.drop_duplicates(subset=['trip_id'])\n",
    "\n",
    "tmd_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmd_df1= tmd_df1.groupby(['year', 'travel_mode']).size().unstack().fillna(0).apply(lambda x: x/x.sum(), axis=1) * 100\n",
    "tmd_df2= tmd_df2.groupby(['year', 'travel_mode']).size().unstack().fillna(0).apply(lambda x: x/x.sum(), axis=1) * 100\n",
    "tmd_df3= tmd_df3.groupby(['year', 'travel_mode']).size().unstack().fillna(0).apply(lambda x: x/x.sum(), axis=1) * 100\n",
    "tmd_df4= tmd_df4.groupby(['year', 'travel_mode']).size().unstack().fillna(0).apply(lambda x: x/x.sum(), axis=1) * 100\n",
    "tmd_df5= tmd_df5.groupby(['year', 'travel_mode']).size().unstack().fillna(0).apply(lambda x: x/x.sum(), axis=1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmd_df = pd.concat([tmd_df1, tmd_df2, tmd_df3, tmd_df4, tmd_df5], axis=0)\n",
    "# make the df have two decimal points\n",
    "tmd_df = tmd_df.round(2)\n",
    "tmd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "travel-mode-detection-WRfcnI0A-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
