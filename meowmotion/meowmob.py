import json
from datetime import datetime
from multiprocessing import Pool, cpu_count
from typing import Tuple

import geopandas as gpd
import pandas as pd
from skmob import TrajDataFrame
from skmob.preprocessing import detection
from tqdm import tqdm

from meowmotion.process_data import getLoadBalancedBuckets, saveFile, spatialJoin


def getStopNodes(tdf: TrajDataFrame, time_th: int, radius: int) -> pd.DataFrame:
    """

    This function takes a TrajDataFrame and returns the stop nodes data. The stop nodes data contains the following columns:
    uid, org_lat, org_lng, org_arival_time, org_leaving_time, dest_lat, dest_lng, dest_arival_time.
    This function uses the stay_locations function from the skmob library to detect the stop nodes.

    Args:
        tdf (TrajDataFrame): TrajDataFrame containing the trajectory data.
        time_th (int): Time threshold in minutes.
        radius (int): Radius in meters.

    Returns:
        pd.DataFrame: Stop nodes data.

    Example:
        >>> getStopNodes(tdf, time_th, radius)
    """

    return detection.stay_locations(
        tdf,
        minutes_for_a_stop=time_th,
        spatial_radius_km=(radius / 1000),
        leaving_time=True,
    )


def processFlowGenration(stdf: pd.DataFrame, raw_df: TrajDataFrame) -> pd.DataFrame:
    """

    This function generates the flow data from the stop nodes data. It takes the stop nodes data and the raw data as input and returns the flow data.
    The flow data contains the following columns:
    uid, org_lat, org_lng, org_arival_time, org_leaving_time, dest_lat, dest_lng, dest_arival_time, stay_points, trip_points, trip_time, stay_duration, observed_stay_duration
    The function uses the following steps to generate the flow data:
        1. It takes the stop nodes data and the raw data as input.
        2. It iterates through the stop nodes data and for each row, it fetches the data from the raw data.
        3. It appends the data to a list.
        4. It converts the list to a DataFrame.
        5. It returns the DataFrame.

    Args:
        stdf (pd.DataFrame): Stop nodes data.
        raw_df (TrajDataFrame): Raw data.

    Returns:
        pd.DataFrame: Flow data.

    Example:
        >>> processFlowGenration(stdf, raw_df)

    """

    flow_df = []
    cols = [
        "uid",
        "org_lat",
        "org_lng",
        "org_arival_time",
        "org_leaving_time",
        "dest_lat",
        "dest_lng",
        "dest_arival_time",
        "stay_points",
        "trip_points",
        "trip_time",
        "stay_duration",
        "observed_stay_duration",
    ]
    for ind, row in tqdm(stdf.iterrows()):
        flow_df.append(fetchDataFromRaw(row, raw_df))

    # Converting list to Dataframe
    flow_df = pd.DataFrame(flow_df, columns=cols)

    return flow_df


def fetchDataFromRaw(record: pd.Series, raw_df: TrajDataFrame) -> list:
    """

    This function fetches the data from the raw data based on the stop nodes data. It takes the stop nodes data and the raw data as input and returns the flow data.
    The flow data contains the following columns:
    uid, org_lat, org_lng, org_arival_time, org_leaving_time, dest_lat, dest_lng, dest_arival_time, stay_points, trip_points, trip_time, stay_duration, observed_stay_duration

    Args:
        record (pd.Series): Stop nodes data.
        raw_df (TrajDataFrame): Raw data.

    Returns:
        list: Flow data.

    Example:
        >>> fetchDataFromRaw(record, raw_df)
    """

    org_at = record["datetime"]  # Origin arriving time
    org_lt = record["leaving_datetime"]  # origin leaving time
    dest_at = record["dest_at"]  # destination arriving time

    stay_points = json.dumps(
        raw_df.loc[(record["uid"], org_at) : (record["uid"], org_lt)][["lat", "lng"]]
        .values[0:-1]
        .tolist()
    )  # points inside the stop nodes= all the points between the time of first point inside cluster and time of first point outside the cluster
    trip_points = json.dumps(
        raw_df.loc[(record["uid"], org_lt) : (record["uid"], dest_at)][["lat", "lng"]]
        .values[0:-1]
        .tolist()
    )  # points in between two stop nodes= all the points between the time of first point outside the origin stay node and the time of first point inside the destination stop node

    stay_duration = round(
        (org_lt - org_at).total_seconds() / 60
    )  # How long stay inside the stop node (calculated using the leaving time generated by Scikit-mob)= The time of the first point outside the stop node - the time of the first point inside the stop node
    org_last_point_time = raw_df.loc[(record["uid"], org_at) : (record["uid"], org_lt)][
        ["lat", "lng"]
    ].index.tolist()[-2][
        1
    ]  # Time of the last point inside the stop node
    observed_stay_duration = (
        org_last_point_time - org_at
    ).total_seconds() / 60  # observed stay= The time of the last point inside the stop node - the time of the first point inside the stop node

    trip_time = round(
        (dest_at - org_lt).total_seconds() / 60
    )  # Trip time= destination arrival time - orgin leaving time

    temp = [
        record["uid"],
        record["org_lat"],  # org_lat,
        record["org_lng"],  # org_lng,
        org_at,
        org_lt,
        record["dest_lat"],  # dst_lat,
        record["dest_lng"],  # dst_lng,
        dest_at,
        stay_points,
        trip_points,
        trip_time,
        stay_duration,
        observed_stay_duration,
    ]
    return temp


def generateOD(
    trip_df: pd.DataFrame,
    shape: gpd.GeoDataFrame,
    active_day_df: pd.DataFrame,
    org_loc_cols: Tuple[str, str],  # (lng, lat)
    dest_loc_cols: Tuple[str, str],  # (lng, lat)
    output_dir: str,
    cpu_cores: int = max(1, cpu_count() // 2),
) -> None:

    print(shape.crs)
    shape = shape.to_crs("EPSG:4326")
    print(f"{datetime.now()}: Indexing Shape File")
    shape.sindex

    #############################################################
    #                                                           #
    #                   Spatial Join for Origin                 #
    #                                                           #
    #############################################################

    df_collection = getLoadBalancedBuckets(trip_df, cpu_cores)
    print(f"{datetime.now()}: Spatial Join for Origin Started")
    # args=[(tdf, shape, 'org_lng', 'org_lat', 'origin') for tdf in df_collection]
    args = [
        (tdf, shape, org_loc_cols[0], org_loc_cols[1], "origin")
        for tdf in df_collection
    ]
    with Pool(cpu_cores) as pool:
        results = pool.starmap(spatialJoin, args)
    df_collection = [*results]
    print(f"{datetime.now()}: Spatial Join for Origin Finished")

    #############################################################
    #                                                           #
    #                  Spatial Join for Destination             #
    #                                                           #
    #############################################################

    print(f"{datetime.now()}: Spatial Join for Destination Started")
    # args=[(tdf, shape, 'dest_lng', 'dest_lat', 'destination') for tdf in df_collection]
    args = [
        (tdf, shape, dest_loc_cols[0], dest_loc_cols[1], "destination")
        for tdf in df_collection
    ]
    with Pool(cpu_cores) as pool:
        results = pool.starmap(spatialJoin, args)
    geo_df = pd.concat([*results])
    del results
    print(f"{datetime.now()}: Spatial Join for Destination Finished")
    #############################################################
    #                                                           #
    # Filtering trips based on travel time and stay duration    #
    #                                                           #
    #############################################################

    print(f"{datetime.now()}: Filtering on Travel Time and Stay Duration")
    geo_df = geo_df[
        (geo_df["dest_arival_time"] - geo_df["org_leaving_time"]).dt.total_seconds()
        / 3600
        <= 24
    ]
    geo_df = geo_df[geo_df["stay_duration"] <= 3600]
    nusers = geo_df["uid"].nunique()
    print(f"{datetime.now()}: Total Unique Users: {nusers}")

    print(geo_df[~geo_df["origin_geo_code"].isna()].head())

    geo_df["origin_geo_code"] = geo_df["origin_geo_code"].fillna("Others")
    geo_df["destination_geo_code"] = geo_df["destination_geo_code"].fillna("Others")
    geo_df = geo_df[geo_df["origin_geo_code"] != "Others"]
    geo_df = geo_df[geo_df["destination_geo_code"] != "Others"]
    print(f"{datetime.now()}: Filtering Completed")

    #############################################################
    #                                                           #
    #                   Disclosure Analysis                     #
    #                                                           #
    #############################################################

    print(f"{datetime.now()}: Generating file for disclosure analysis")
    analysis_df = (
        geo_df.groupby(["origin_geo_code", "destination_geo_code"])
        .agg(
            total_trips=pd.NamedAgg(column="uid", aggfunc="count"),
            num_users=pd.NamedAgg(column="uid", aggfunc="nunique"),
        )
        .reset_index()
    )

    print(f"{datetime.now()}: Saving disclosure analysis file")
    saveFile(path=output_dir, fname="disclosure_analysis_.csv", df=analysis_df)
    print(f"{datetime.now()}: Saved disclosure analysis file")

    ############################################################
    #                                                          #
    #                   Adding Trip ID                         #
    #                                                          #
    ############################################################

    print(f"{datetime.now()}: Adding Trip ID")
    geo_df = geo_df.assign(
        trip_id=lambda df: df.groupby(["uid"])["trip_time"].transform(
            lambda x: [i for i in range(1, len(x) + 1)]
        )
    )

    # first_cols = ['uid', 'trip_id']
    # other_cols = [col for col in geo_df.columns if col not in first_cols]
    # geo_df = geo_df[first_cols + other_cols]

    geo_df = geo_df[
        [
            "uid",
            "trip_id",
            "org_lat",
            "org_lng",
            "org_arival_time",
            "org_leaving_time",
            "dest_lat",
            "dest_lng",
            "dest_arival_time",
            "stay_points",
            "trip_points",
            "trip_time",
            "stay_duration",
            "observed_stay_duration",
            "origin_geo_code",
            "origin_name",
            "destination_geo_code",
            "destination_name",
        ]
    ]
    print(f"{datetime.now()}: Trip ID Added")

    #############################################################
    #                                                           #
    #                    Calculate Total Trips/User             #
    #                                                           #
    #############################################################

    print(f"{datetime.now()}: Calculating Total Trips/User")
    geo_df["month"] = geo_df["org_leaving_time"].dt.month
    geo_df = geo_df.assign(
        total_trips=lambda df: df.groupby("uid")["trip_id"].transform(lambda x: len(x))
    )
    geo_df = geo_df.drop(columns=["month"])
    print(f"{datetime.now()}: Trips/User Calculated")

    #############################################################
    #                                                           #
    #                   Add Trips/Active Day                    #
    #                                                           #
    #############################################################

    print(f"{datetime.now()}: Calculating TPAD")
    geo_df = geo_df.merge(active_day_df, how="left", on="uid").assign(
        tpad=lambda tdf: tdf["total_trips"] / tdf["total_active_days"]
    )
    print(f"{datetime.now()}: TPAD Calculated")

    return None
